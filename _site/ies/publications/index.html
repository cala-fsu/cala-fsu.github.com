<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-type" content="text/html; charset=utf-8" />
	<meta http-equiv="Content-Language" content="en-us" />
	<meta name="Language" content="english" />
	<meta name="description" content="Welcome to the Center for Advancement of Learning and Assessment (CALA) Web site." />
	<meta name="keywords" content="CALA, FSU, Florida State University" />
    <title>Improving Science Assessments &ndash; Publications</title>

	<!--[if gte IE 6]><!-->
    <link href="/stylesheets/screen.css" media="screen" rel="stylesheet" type="text/css" />
    <link href="/stylesheets/print.css" media="print" rel="stylesheet" type="text/css" />
	<!-- <![endif]-->

	<!--[if IE 6]>
    <link href="/stylesheets/ie6.css" media="screen" rel="stylesheet" type="text/css" />
	<![endif]-->

	<link rel="shortcut icon" type="image/ico" href="/favicon.ico" />

</head>
<body id="ies">
	<div id="wrapper">
		<p class="skipNav">
			<a href="#contentWrapper">Skip Navigation</a>
		</p>
		<div id="masthead">
			<div id="logo"></div>
            <img url="/images/print_style_banner.jpg" id="printLogo" />
			<div id="navbar">
				<p id="title">Center for Advancement of Learning and Assessment</p>
                <a href="http://www.fsu.edu/" id="fsu">Florida State University</a>
				<!-- <ul>
                    <li id="homeNav"><a href="/">home</a></li>
                    <li id="servicesNav"><a href="/services/research/">services</a></li>
                    <li id="aboutNav"><a href="/about/cala/">about</a></li>
                    <li id="portfolioNav"><a href="/portfolio/">portfolio</a></li>
                    <li id="newsNav"><a href="/news/">news</a></li>
				</ul> -->
			</div>
		</div>
		<div id="contentWrapper">
            
<div id="subnav">
    <ul>
        <li id="" ><a href="/ies/">Overview</a></li>
        <li id="" ><a href="/ies/project_news/">Project News</a></li>
        <li id="" ><a href="/ies/training/">Training</a></li>
        <li id="selected" ><a href="/ies/publications/">Publications</a></li>
        <li id="" ><a href="/ies/resources/">Resources</a></li>
        <li id="" ><a href="/ies/research_team/">Research Team</a></li>
    </ul>
</div>


<div id="singleContent">
    <div id="iesPublications">
        <p id="iesTagLine">Improving Science Assessments</p>
        <h1>Publications</h1>
        <ul>
            <li>
                <h2><a href='/files/high-stakes_assessment.pdf'>Upgrading High-Stakes Assessments</a></h2>
                <p>Because of the large number of students involved, statewide assessments used throughout the United States
                are designed to be highly efficient with respect to administration and scoring. This constrains the formats
                that can be used and thus limits testing to a subset of competencies typically associated with the education
                standards being assessed. CALA is developing an alternative approach that is designed to help expand the range
                of skills evaluated by statewide assessments and add a formative aspect to these assessments.
                <a href='/files/high-stakes_assessment.pdf'>Read the paper&#8230;</a></p>
            </li>
            <li>
                <h2><a href='/files/ccm.pdf'>The Capabilities-Complexity Model</a></h2>
                <p>In assessment, the ability to construct test items that measure a targeted skill is fundamental to validity and
                alignment. The ability to do the reverse is also important: determining what skill an existing test item measures.
                This paper presents a model for classifying test items that builds on procedures developed by others, including
                Bloom (1956) and Webb (2002). An advantage of the proposed model is that it references both the type of cognitive
                ability involved and the complexity of skill being assessed. This model is referred to as the Capabilities-Complexity
                Model. <a href='/files/ccm.pdf'>Read the paper&#8230;</a></p>
            </li>
            <li>
                <h2><a href='/files/unassessed_competencies.pdf'>Science Competencies That Go Unassessed</a></h2>
                <p>Researchers at CALA are examining options for upgrading high-stakes, statewide assessments in middle school
                science. During the research, strategies will be devised for measuring critical science competencies that are not
                measured within conventional large-scale testing programs. <em>Science Competencies That Go Unassessed</em>
                identifies the seventh-grade science knowledge and skills implicit in Florida’s current Sunshine State Standards
                that cannot be measured by the Florida Comprehensive Assessment Test. The identified competencies will become the
                subsequent focus of our complex science assessments.
                <a href='/files/unassessed_competencies.pdf'>Read the paper&#8230;</a></p>
            </li>
            <li>
                <h2><a href='/ies/performance_assessment_specifications/'>Specifications for Complex Science Assessments</a></h2>
                <p>CALA is designing a series of performance assessment specifications for middle school science. Teachers and
                project researchers are using these specifications to independently design summative performance assessments
                that measure critical competencies not assessed by conventional large-scale tests such as the Florida Comprehensive
                Assessment Test. Teachers also are using the specifications to create separate assessments for formative use
                during instruction. Eight specifications have been developed during the first two years of the project, including
                sample performance assessments and scoring plans.
                <a href='/ies/performance_assessment_specifications/'>View the specifications&#8230;</a></p>
            </li>
            <li>
                <h2><a href='/files/Enriching Assessment of the Core 2012-08-28 - final version.pptx'>
                    Enriching Assessment of the Core</a></h2>
                <p>This is an invited presentation made at the September 2012 IES Principal Investigators' meeting in Washington, DC.
                The presentation was part of a panel session titled “Shifting Sands: How Do Researchers Respond to Changing Standards
                and Assessments.” The session focused on challenges researchers face as a result of the shifts in state standards and
                assessments, along with potential responses. The primary purpose of the present presentation is to describe a strategy
                being examined by one IES project for expanding the types of science competencies that are included in both
                large-scale assessments such as those administered statewide and classroom assessments that are developed and
                administered by teachers. The assessment strategy includes significant formative and summative components.
                <a href='/files/Enriching Assessment of the Core 2012-08-28 - final version.pptx'>View the presentation&#8230;</a></p>
            </li>
			<li>
				<h2><a href='/files/g-theory_report.pdf'>Reliability of Scores on the Summative Performance Assessments</a></h2>
				<p>Reliability is concerned with the consistency of a measure. Examining reliability is important, in part, because the 
					presence of inconsistencies indicates that something is influencing observations unrelated to what supposedly is being measured. 
					This, in turn, represents a direct threat to an assessment’s validity. This paper reports results of reliability studies that 
					were conducted during our project’s pilot year. Generalizability theory was used as the framework for these studies because 
					of the flexibility this approach provides for examining sources of inconsistency within a complex assessment. 
					<a href='/files/g-theory_report.pdf'>Read the paper&#8230;</a></p>
			</li>	
            <li>
                <h2><a href='/files/declarative_knowledge.pdf'>Types of Changes That Occur as Declarative Knowledge Increases</a></h2>
                <p>Chi and Ohlsson (2005) propose seven types of changes that occur as declarative knowledge increases. As our
                project team develops middle-school science assessments, these changes provide our framework for selecting student
                tasks whenever the focus of the assessment is on declarative knowledge. A given assessment, however, typically
                addresses a subset of the seven types. This paper provides a summary description of each type of change and offers
                illustrations relevant to science education.
                <a href='/files/declarative_knowledge.pdf'>Read the paper&#8230;</a></p>
            </li>
            <li>
                <h2><a href='/files/science_assessment_strategy.pdf'>A Strategy for Large-Scale Science Assessment</a></h2>
                <p>Our research seeks to determine the feasibility of a strategy that would expand the range of skills evaluated
                by large-scale assessment programs. Sampling, item specifications, and formative assessment training are designed
                to make performance measures more cost effective and the results more instructionally useful. This paper
                summarizes the first six months of the study, focusing on seventh-grade science competencies.
                <a href='/files/science_assessment_strategy.pdf'>Read the paper&#8230;</a></p>
            </li>
        </ul>
    </div>
</div>

		</div>
	</div>
</body>
</html>
