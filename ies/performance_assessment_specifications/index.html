---
layout: default
title: Improving Science Assessments &ndash; Performance Assessment Specifications
id: ies
---
{% assign active_subnav_item = 'publications' %}
{% include ies_subnav.html %}

<div id="singleContent">
    <div id="iesPerformanceAssessmentSpecifications">
        <h1>Performance Assessment Specifications&mdash;Phase I and Phase II</h1>

        <p>A <strong>performance assessment specification</strong> provides a recipe for producing a set of parallel performance
        assessments. Each of our specifications describes evidence that will be used to estimate student proficiency with one
        competency or, in some cases, a pair of closely related competencies. Each specification guides the development of parallel
        assessments through establishing common parameters for tasks associated with the competency.</p>

        <p>Following are links to eight performance assessment specifications and the competency or competencies each address.
        The format and substance of these specifications remain under development and may be modified during the course of our
        research.</p>

        <ul id="iesSpecifications">
            <li><a href='/files/Spec 1 - Formulating Testable Question - 4-2-13.pdf'>
                Specification 1: Formulating a Scientifically Testable Question</a>
                <ul>
                    <li>Student can formulate a scientifically testable question(s) that relates to the context or data provided.</li>
                </ul>
            </li>
            <li><a href='/files/Spec 2 - Creating Scientific Investigation - 4-5-13.pdf'>
                Specification 2: Creating a Plan for a Scientific Investigation</a>
                <ul>
                    <li>Student can create a plan for carrying out a scientific investigation, including what, when, and how to measure
                    variables.</li>
                </ul>
            </li>
            <li><a href='/files/Spec 3 - Organizing Data - 6-21-12.pdf'>
                Specification 3: Organizing and Making Inferences/Predictions from Data</a>
                <ul>
                    <li>Student can organize data by creating a table, chart, or other representation to facilitate interpretation.</li>
                    <li>Student can make inferences and predictions and use the data to defend or refute conclusions.</li>
                </ul>
            </li>
            <li><a href='/files/Spec 4 - Observing Limiting Factors - 4-5-13.pdf'>
                Specification 4: Observing/Determining Limiting Factors of an Ecosystem</a>
                <ul>
                    <li>Student can observe and describe a local ecosystem.</li>
                    <li>Student can determine potential limiting factors for specified populations in a local ecosystem.</li>
                </ul>
            </li>
            <li><a href='/files/Spec 5 - Conducting Measurements - 8-10-12.pdf'>
                Specification 5: Conducting Scientific Measurements</a>
                <ul>
                    <li>Student can carry out a plan for scientific investigations of various types.</li>
                </ul>
            </li>
            <li><a href='/files/Spec 6 - Complex Biological Relationships - 4-5-13.pdf'>
                Specification 6: Explaining Complex Biological Relationships</a>
                <ul>
                    <li>Student can explain complex relationships between biotic and abiotic factors in an ecosystem.</li>
                </ul>
            </li>
            <li><a href='/files/Spec 7 - Creating Food Web - 4-2-13.pdf'>
                Specification 7: Drawing a Food Web</a>
                <ul>
                    <li>Student can create a diagram (i.e., food web) that illustrates the flow of energy among producers,
                    consumers, and decomposers within an ecosystem.</li>
                </ul>
            </li>
            <li><a href='/files/Spec 8 - Investigating Limiting Factors - 4-5-13.pdf'>
                Specification 8: Investigating Limiting Factors</a>
                <ul>
                    <li>Student can investigate multiple factors that impact native populations in the ecosystem.</li>
                </ul>
            </li>
            <li><a href='/files/Spec 9 - Differentiating Theory and Law - 6-26-13.pdf'>Specification 9: Differentiating Theory and Law</a>
                <ul>
                    <li>Student can explain the difference between theories and laws.</li>
                </ul>
            </li>
            <li><a href='/files/Spec 10 - Supporting a Scientific Theory with Evidence - 6-26-13.pdf'>Specification 10: Supporting a Scientific Theory with Evidence</a>
                <ul>
                    <li>Student can provide examples of evidence that support a scientific theory.</li>
                </ul>
            </li>    
        </ul>

        <p>Our specifications incorporate the broad framework suggested by evidence-centered design (ECD; see, for example, Mislevy,
        Almond, &amp; Lukas, 2003) in which educational assessments are constructed in terms of evidentiary arguments. Principal
        components within the ECD approach include establishing <strong>competencies</strong> to be assessed (descriptions of
        particular mental abilities or skills students are expected to develop), identifying directly observable
        <strong>evidence</strong> upon which an inference of student proficiency with a particular competency can be made, and
        developing <strong>tasks</strong> that students will perform (such as a specific test item or performance assessment)
        through which the observable evidence can be derived.</p>

        <p>Therefore, development of an assessment is initiated by first identifying the competency to be assessed. ECD, however,
        is bidirectional in that estimating a student's proficiency with the competency begins with observing the student's
        performance on the task. The establishment of the scoring plan contributes to observable evidence, helping link the
        student's performance on the task to proficiency with the competency.</p>

        <p>A broad range of evidence can be used to establish proficiency with a competency. A particular specification describes
        relevant evidence that the assessment will provide, but alternate evidence might have been used. That is, evidence
        referenced by a specification typically is not exclusive. Furthermore, the specified evidence might not be sufficient by
        itself to establish proficiency with the competency.</p>

        <p>Each of our performance assessment specifications contains the following same components.</p>
        <ul>
          <li><strong>Competency</strong>: Describes an ability related to knowledge and mental skills, typically a target of instruction 
              and related learning&#8212;one cannot directly see what another person knows or is thinking, but relies on behaviors to provide 
              an indication; also indicates the focus of the type of knowledge to be assessed</li>
          <li><strong>Evidence</strong>: Identifies behaviors or performances that will help reveal students’ status with the competency, the 
              connection between those behaviors and the competency, and the nature and form of tasks that will elicit evidence; the evidence 
              statement within a specification typically is not exclusive and may not be comprehensive</li>
          <li><strong>Example task</strong>: Provides a specific example consistent with the evidence statement, of what a student could be 
              asked to do to indicate how well the competency had been achieved</li>
          <li><strong>Scoring plan for the example task</strong>: Establishes a specific procedure consistent with the evidence statement 
              for associating a numerical score with a student’s performance on the example task</li>
          <li><strong>Procedure for creating parallel tasks</strong>: Provides the process for generating a family of parallel tasks that 
              involve the same knowledge or skill associated with the example task, consistent with the evidence statement; includes 
              presentation format (e.g., directions, illustrations, guidelines on information), specific work or response products 
              (e.g., answers, work samples), and other variables used to describe key features of tasks</li>
          <li><strong>Scoring plan for parallel tasks</strong>: Establishes parameters associated with scoring each task generated 
              using the specification, including specific characteristics to be observed and point(s) awarded when each of the 
              respective characteristics is observed in a student’s performance</li>
        </ul>

        <h2>Reference</h2>
        <p>Mislevy, R. J., Almond, R. G., &amp; Lukas, J. F. (2003). <cite>A brief introduction to evidence-centered design</cite>.
        (ETS Research Report RR-03-16). Princeton, NJ: Educational Testing Service. Also available at
        <a href='http://www.ets.org/Media/Research/pdf/RR-03-16.pdf'>http://www.ets.org/Media/Research/pdf/RR-03-16.pdf</a>.</p>
    </div>
</div>
